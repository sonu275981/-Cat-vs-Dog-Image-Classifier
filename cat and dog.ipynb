{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = r'C:\\Users\\sonuc\\Desktop\\Data_Science\\Transpher learning and cat-and-dog SIMPLE\\training_set\\training_set'\n",
    "categories = ['cats','dogs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joining path between dog,cat folder and i by using path.join\n",
    "\n",
    "listing folders using listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in categories:\n",
    "    \n",
    "    paths = os.path.join(dir_path,i)\n",
    "    \n",
    "    for j in os.listdir(paths):\n",
    "        img_path = os.path.join(paths,j)\n",
    "        labels = categories.index(i)\n",
    "        img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img,(150,150))\n",
    "        data.append([img,labels])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8005\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for features,label in data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "#x = np.array(x).reshape(-1, 150, 150, 1)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting lists into numpy arrays\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x).reshape(-1, 150, 150, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train images is: (8005, 150, 150, 1)\n",
      "Shape of labels is: (8005,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train images is:\", x.shape)\n",
    "print(\"Shape of labels is:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64,(3,3), activation='relu', input_shape = (x.shape[1:])))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(1,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 64)      640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               10616960  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 10,654,657\n",
      "Trainable params: 10,654,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "226/226 [==============================] - 15s 48ms/step - loss: 0.6977 - accuracy: 0.5026 - val_loss: 0.6761 - val_accuracy: 0.4794\n",
      "Epoch 2/20\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.6591 - accuracy: 0.5026 - val_loss: 0.6521 - val_accuracy: 0.4794\n",
      "Epoch 3/20\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.5863 - accuracy: 0.5026 - val_loss: 0.6957 - val_accuracy: 0.4794\n",
      "Epoch 4/20\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.4668 - accuracy: 0.5026 - val_loss: 0.6159 - val_accuracy: 0.4794\n",
      "Epoch 5/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.3073 - accuracy: 0.5026 - val_loss: 0.7285 - val_accuracy: 0.4794\n",
      "Epoch 6/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.1485 - accuracy: 0.5026 - val_loss: 0.8842 - val_accuracy: 0.4794\n",
      "Epoch 7/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.0506 - accuracy: 0.5026 - val_loss: 1.2782 - val_accuracy: 0.4794\n",
      "Epoch 8/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.0205 - accuracy: 0.5026 - val_loss: 1.4990 - val_accuracy: 0.4794\n",
      "Epoch 9/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.0045 - accuracy: 0.5026 - val_loss: 1.7720 - val_accuracy: 0.4794\n",
      "Epoch 10/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.0015 - accuracy: 0.5026 - val_loss: 2.0660 - val_accuracy: 0.4794\n",
      "Epoch 11/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 7.9728e-04 - accuracy: 0.5026 - val_loss: 2.0875 - val_accuracy: 0.4794\n",
      "Epoch 12/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 4.3318e-04 - accuracy: 0.5026 - val_loss: 2.1719 - val_accuracy: 0.4794\n",
      "Epoch 13/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 2.9767e-04 - accuracy: 0.5026 - val_loss: 2.2589 - val_accuracy: 0.4794\n",
      "Epoch 14/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 2.1948e-04 - accuracy: 0.5026 - val_loss: 2.3219 - val_accuracy: 0.4794\n",
      "Epoch 15/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 1.6798e-04 - accuracy: 0.5026 - val_loss: 2.3777 - val_accuracy: 0.4794\n",
      "Epoch 16/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 1.3160e-04 - accuracy: 0.5026 - val_loss: 2.4273 - val_accuracy: 0.4794\n",
      "Epoch 17/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 1.0380e-04 - accuracy: 0.5026 - val_loss: 2.4906 - val_accuracy: 0.4794\n",
      "Epoch 18/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 8.4828e-05 - accuracy: 0.5026 - val_loss: 2.5291 - val_accuracy: 0.4794\n",
      "Epoch 19/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 6.9189e-05 - accuracy: 0.5026 - val_loss: 2.5721 - val_accuracy: 0.4794\n",
      "Epoch 20/20\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 5.7045e-05 - accuracy: 0.5026 - val_loss: 2.6138 - val_accuracy: 0.4794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f360db2490>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637470542.3991764"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "CATEGORIES = ['Cat', 'Dog']\n",
    "\n",
    "\n",
    "def image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    new_arr = cv2.resize(img, (150, 150))\n",
    "    new_arr = np.array(new_arr)\n",
    "    new_arr = new_arr.reshape(-1, 150, 150, 1)\n",
    "    return new_arr\n",
    "\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([image('test_of_model/puppy.jpg')])\n",
    "print(CATEGORIES[prediction.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
