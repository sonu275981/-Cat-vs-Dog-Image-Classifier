{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = r'C:\\Users\\sonuc\\Desktop\\Data_Science\\cat-and-dog\\training_set\\training_set'\n",
    "categories = ['cats','dogs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joining path between dog,cat folder and i by using path.join\n",
    "\n",
    "listing folders using listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in categories:\n",
    "    \n",
    "    paths = os.path.join(dir_path,i)\n",
    "    \n",
    "    for j in os.listdir(paths):\n",
    "        img_path = os.path.join(paths,j)\n",
    "        labels = categories.index(i)\n",
    "        img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img,(150,150))\n",
    "        data.append([img,labels])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8005\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for features,label in data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "#x = np.array(x).reshape(-1, 150, 150, 1)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting lists into numpy arrays\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x).reshape(-1, 150, 150, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train images is: (8005, 150, 150, 1)\n",
      "Shape of labels is: (8005,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train images is:\", x.shape)\n",
    "print(\"Shape of labels is:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64,(3,3), activation='relu', input_shape = (x.shape[1:])))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(1,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 64)      640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               10616960  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 10,654,657\n",
      "Trainable params: 10,654,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 0.1953 - accuracy: 0.5015 - val_loss: 0.6355 - val_accuracy: 0.4894\n",
      "Epoch 2/20\n",
      "226/226 [==============================] - 11s 47ms/step - loss: 0.0859 - accuracy: 0.5015 - val_loss: 0.8794 - val_accuracy: 0.4894\n",
      "Epoch 3/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 0.0400 - accuracy: 0.5015 - val_loss: 1.1399 - val_accuracy: 0.4894\n",
      "Epoch 4/20\n",
      "226/226 [==============================] - 11s 47ms/step - loss: 0.0158 - accuracy: 0.5015 - val_loss: 1.2660 - val_accuracy: 0.4894\n",
      "Epoch 5/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 0.0043 - accuracy: 0.5015 - val_loss: 1.4293 - val_accuracy: 0.4894\n",
      "Epoch 6/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 0.0016 - accuracy: 0.5015 - val_loss: 1.5567 - val_accuracy: 0.4894\n",
      "Epoch 7/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 8.8761e-04 - accuracy: 0.5015 - val_loss: 1.6317 - val_accuracy: 0.4894\n",
      "Epoch 8/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 5.9034e-04 - accuracy: 0.5015 - val_loss: 1.7095 - val_accuracy: 0.4894\n",
      "Epoch 9/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 4.0102e-04 - accuracy: 0.5015 - val_loss: 1.7669 - val_accuracy: 0.4894\n",
      "Epoch 10/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 2.9616e-04 - accuracy: 0.5015 - val_loss: 1.7999 - val_accuracy: 0.4894\n",
      "Epoch 11/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 2.2604e-04 - accuracy: 0.5015 - val_loss: 1.8425 - val_accuracy: 0.4894\n",
      "Epoch 12/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 1.8033e-04 - accuracy: 0.5015 - val_loss: 1.8802 - val_accuracy: 0.4894\n",
      "Epoch 13/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 1.4643e-04 - accuracy: 0.5015 - val_loss: 1.9186 - val_accuracy: 0.4894\n",
      "Epoch 14/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 1.1877e-04 - accuracy: 0.5015 - val_loss: 1.9466 - val_accuracy: 0.4894\n",
      "Epoch 15/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 9.7924e-05 - accuracy: 0.5015 - val_loss: 1.9831 - val_accuracy: 0.4894\n",
      "Epoch 16/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 7.9177e-05 - accuracy: 0.5015 - val_loss: 2.0096 - val_accuracy: 0.4894\n",
      "Epoch 17/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 6.5291e-05 - accuracy: 0.5015 - val_loss: 2.0410 - val_accuracy: 0.4894\n",
      "Epoch 18/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 5.5205e-05 - accuracy: 0.5015 - val_loss: 2.0646 - val_accuracy: 0.4894\n",
      "Epoch 19/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 4.5994e-05 - accuracy: 0.5015 - val_loss: 2.0859 - val_accuracy: 0.4894\n",
      "Epoch 20/20\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 3.9277e-05 - accuracy: 0.5015 - val_loss: 2.1144 - val_accuracy: 0.4894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f45d4151c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "CATEGORIES = ['Cat', 'Dog']\n",
    "\n",
    "\n",
    "def image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    new_arr = cv2.resize(img, (150, 150))\n",
    "    new_arr = np.array(new_arr)\n",
    "    new_arr = new_arr.reshape(-1, 150, 150, 1)\n",
    "    return new_arr\n",
    "\n",
    "model = keras.models.load_model('3x3x64-catvsdog.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([image('test_of_model/puppy.jpg')])\n",
    "print(CATEGORIES[prediction.argmax()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
